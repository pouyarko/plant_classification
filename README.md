First, the dataset was downloaded from Kaggle.com, which included 36 classes. Due to the small number of images in some classes, those classes were removed, leaving 27 classes. The data was divided into three separate parts: train, validation, and test, using the train_test_split function. A Python generator object was written to provide data from each class according to the batch size. At each step, the remaining data in the class was compared with the batch size. If there was enough data, that data was returned; if the class data was exhausted, it was returned to the beginning of the class (a method of oversampling).

Next, a simple model with a CNN architecture that includes dilation (there are gaps between the pixels in the kernel) was built. The model was trained and saved after each epoch. Finally, the model was evaluated on the test data (accuracy = 0.86, categorical loss = 0.47). A pre-trained model was also loaded for example purposes, similar to the paper, which is ready for fine-tuning.
